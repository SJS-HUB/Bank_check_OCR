{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "!pip install openai pandas pdf2image"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "import openai, json, pandas as pd\nfrom PIL import Image\nfrom pdf2image import convert_from_path\nimport base64, os\n\nopenai.api_key = \"sk-...\"  # Replace with your actual key"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "def convert_pdf_to_images(pdf_folder_path, image_output_folder):\n    os.makedirs(image_output_folder, exist_ok=True)\n    all_images = []\n    for file in os.listdir(pdf_folder_path):\n        if file.endswith(\".pdf\"):\n            pages = convert_from_path(os.path.join(pdf_folder_path, file), dpi=300)\n            for i, page in enumerate(pages):\n                image_path = os.path.join(image_output_folder, f\"{file[:-4]}_page_{i+1}.jpg\")\n                page.save(image_path, \"JPEG\")\n                all_images.append(image_path)\n    return all_images"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "def extract_text_from_image_with_gpt_vision(image_path):\n    with open(image_path, \"rb\") as image_file:\n        image_bytes = image_file.read()\n        base64_image = base64.b64encode(image_bytes).decode('utf-8')\n\n    response = openai.ChatCompletion.create(\n        model=\"gpt-4-vision-preview\",\n        messages=[\n            {\"role\": \"system\", \"content\": \"You are an OCR assistant for extracting clean, readable text from loan-related cheque images.\"},\n            {\n                \"role\": \"user\",\n                \"content\": [\n                    {\"type\": \"text\", \"text\": \"Extract all visible text from this cheque image.\"},\n                    {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_image}\" }}\n                ]\n            }\n        ],\n        max_tokens=1024\n    )\n    ocr_text = response.choices[0].message.content.strip()\n    tokens_used = response.usage.total_tokens\n    return ocr_text, tokens_used"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "def parse_cheque_text_via_gpt(ocr_text: str) -> tuple:\n    system_msg = \"You are a data extraction assistant. Extract loan cheque information.\"\n\n    user_msg = f\"\"\"Extract the following fields and return in JSON format:\n    - Date\n    - Payee Name\n    - Amount\n    - Loan Account Number\n    - IFSC Code\n    - MICR Code\n\n    OCR Text:\n    {ocr_text}\n    \"\"\"\n    response = openai.ChatCompletion.create(\n        model=\"gpt-3.5-turbo\",\n        messages=[\n            {\"role\": \"system\", \"content\": system_msg},\n            {\"role\": \"user\", \"content\": user_msg}\n        ],\n        temperature=0\n    )\n    parsed_json = response['choices'][0]['message']['content']\n    tokens_used = response.usage.total_tokens\n    return json.loads(parsed_json), tokens_used"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "def process_cheques_and_export(image_paths, output_file=\"loan_cheques_parsed.xlsx\"):\n    records = []\n    total_tokens_vision = 0\n    total_tokens_parse = 0\n\n    for path in image_paths:\n        print(f\"Processing: {path}\")\n        ocr_text, tokens_vision = extract_text_from_image_with_gpt_vision(path)\n        parsed, tokens_parse = parse_cheque_text_via_gpt(ocr_text)\n        parsed['Source Image'] = os.path.basename(path)  # Internal tracking only\n        records.append(parsed)\n        total_tokens_vision += tokens_vision\n        total_tokens_parse += tokens_parse\n\n    df = pd.DataFrame(records)\n\n    # Drop 'Source Image' before export\n    if 'Source Image' in df.columns:\n        df.drop(columns=['Source Image'], inplace=True)\n\n    df.to_excel(output_file, index=False)\n\n    # Estimate costs (token-based)\n    cost_inr_vision = (total_tokens_vision / 1000) * 0.85  # INR\n    cost_inr_parse = (total_tokens_parse / 1000) * 0.04    # INR\n    total_cost_inr = cost_inr_vision + cost_inr_parse\n\n    print(f\"\u2705 Exported to {output_file}\")\n    print(f\"\ud83d\udcca Total GPT-4 Vision tokens: {total_tokens_vision} (~\u20b9{cost_inr_vision:.2f})\")\n    print(f\"\ud83e\udde0 Total GPT-3.5 tokens: {total_tokens_parse} (~\u20b9{cost_inr_parse:.2f})\")\n    print(f\"\ud83e\uddfe Total Estimated Cost: \u20b9{total_cost_inr:.2f} INR for {len(image_paths)} cheques\")"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "pdf_folder = \"pdfs\"  # folder with cheque PDFs\nimage_folder = \"images\"\n\nimage_files = convert_pdf_to_images(pdf_folder, image_folder)\nprocess_cheques_and_export(image_files)"}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"file_extension": ".py", "mimetype": "text/x-python", "name": "python", "version": "3.8"}}, "nbformat": 4, "nbformat_minor": 5}